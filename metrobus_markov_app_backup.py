"""
Aplicaci√≥n interactiva para an√°lisis de cadenas de Markov del Metrob√∫s CDMX
Analiza patrones de transici√≥n entre estaciones usando datos GTFS
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import seaborn as sns
import matplotlib.pyplot as plt
from pathlib import Path
import json
from typing import Dict, List, Tuple
import networkx as nx
from datetime import datetime, timedelta

# Configuraci√≥n de la p√°gina
st.set_page_config(
    page_title="Metrob√∫s CDMX - An√°lisis Markov",
    page_icon="üöå",
    layout="wide",
    initial_sidebar_state="expanded"
)

class MetrobusMarkovAnalyzer:
    """Analizador de cadenas de Markov para datos del Metrob√∫s"""
    
    def __init__(self, data_path: str = "data"):
        self.data_path = Path(data_path)
        self.stops_df = None
        self.routes_df = None
        self.stop_times_df = None
        self.trips_df = None
        self.transition_matrix = None
        self.states = None
    
    def load_data(self):
        """Carga los datos GTFS del Metrob√∫s"""
        try:
            # Usar rutas relativas desde el directorio actual
            stops_file = self.data_path / "stops.txt"
            routes_file = self.data_path / "routes.txt"
            stop_times_file = self.data_path / "stop_times.txt"
            trips_file = self.data_path / "trips.txt"
            
            # Verificar que los archivos existan
            missing_files = []
            for file_path, name in [(stops_file, "stops.txt"), (routes_file, "routes.txt"), 
                                   (stop_times_file, "stop_times.txt"), (trips_file, "trips.txt")]:
                if not file_path.exists():
                    missing_files.append(str(file_path))
            
            if missing_files:
                st.error(f"‚ùå Archivos no encontrados: {', '.join(missing_files)}")
                st.error(f"üìÅ Directorio actual: {Path.cwd()}")
                st.error(f"üîç Buscando en: {self.data_path.absolute()}")
                return False
            
            self.stops_df = pd.read_csv(stops_file)
            self.routes_df = pd.read_csv(routes_file)
            self.stop_times_df = pd.read_csv(stop_times_file)
            self.trips_df = pd.read_csv(trips_file)
              st.success(f"‚úÖ Datos cargados: {len(self.stops_df)} estaciones, {len(self.routes_df)} rutas")
            return True
        except Exception as e:
            st.error(f"Error cargando datos: {e}")
            st.error(f"Directorio actual: {Path.cwd()}")
            st.error(f"Buscando en: {self.data_path}")
            # Asegurar que las variables queden en None si hay error
            self.stops_df = None
            self.routes_df = None
            self.stop_times_df = None
            self.trips_df = None
            return False
    
    def is_data_loaded(self):
        """Verifica si los datos han sido cargados correctamente"""
        return (self.stops_df is not None and 
                self.routes_df is not None and 
                self.stop_times_df is not None and 
                self.trips_df is not None)
    
    def preprocess_data(self, limit_trips=None):
        """Preprocesa los datos para an√°lisis de Markov"""
        if not self.is_data_loaded():
            raise ValueError("Los datos no han sido cargados. Llama a load_data() primero.")
        
        # Unir datos para obtener secuencias de paradas por viaje
        trip_sequences = []
        
        # Obtener todos los trip_ids √∫nicos
        unique_trips = self.stop_times_df['trip_id'].unique()
        
        # Si se especifica un l√≠mite, usarlo; si no, procesar todos
        if limit_trips is not None:
            unique_trips = unique_trips[:limit_trips]
            st.info(f"üîÑ Procesando {len(unique_trips)} viajes de {len(self.stop_times_df['trip_id'].unique())} totales...")
        else:
            st.info(f"üîÑ Procesando TODOS los {len(unique_trips)} viajes disponibles...")
        
        # Optimizaci√≥n: usar groupby para procesar m√°s eficientemente
        progress_bar = st.progress(0)
        total_trips = len(unique_trips)
        
        for i, trip_id in enumerate(unique_trips):
            # Actualizar barra de progreso cada 1000 viajes
            if i % 1000 == 0:
                progress_bar.progress(i / total_trips)
            
            trip_stops = self.stop_times_df[
                self.stop_times_df['trip_id'] == trip_id
            ].sort_values('stop_sequence')
            
            if len(trip_stops) > 1:
                stop_sequence = trip_stops['stop_id'].tolist()
                trip_sequences.append(stop_sequence)
        
        progress_bar.progress(1.0)
        st.success(f"‚úÖ Procesados {len(trip_sequences)} viajes v√°lidos")
        
        return trip_sequences
    
    def estimate_transition_matrix(self, sequences: List[List[str]]) -> np.ndarray:
        """Estima la matriz de transici√≥n entre estaciones"""
        # Obtener todas las estaciones √∫nicas
        all_stops = set()
        for seq in sequences:
            all_stops.update(seq)
        
        self.states = sorted(list(all_stops))
        state_to_idx = {state: i for i, state in enumerate(self.states)}
        n_states = len(self.states)
        
        # Matriz de conteos
        transition_counts = np.zeros((n_states, n_states))
        
        # Contar transiciones
        for seq in sequences:
            for i in range(len(seq) - 1):
                from_idx = state_to_idx[seq[i]]
                to_idx = state_to_idx[seq[i + 1]]
                transition_counts[from_idx, to_idx] += 1
        
        # Normalizar para obtener probabilidades
        row_sums = transition_counts.sum(axis=1)
        # Evitar divisi√≥n por cero
        row_sums[row_sums == 0] = 1
        self.transition_matrix = transition_counts / row_sums[:, np.newaxis]
        
        return self.transition_matrix
    
    def get_stop_name(self, stop_id: str) -> str:
        """Obtiene el nombre de una estaci√≥n por su ID"""
        if self.stops_df is not None:
            stop_info = self.stops_df[self.stops_df['stop_id'] == stop_id]
            if not stop_info.empty:
                return stop_info.iloc[0]['stop_name']
        return stop_id
    
    def simulate_markov_chain(self, start_state: str, n_steps: int = 10) -> List[str]:
        """Simula una cadena de Markov desde un estado inicial"""
        if self.transition_matrix is None or self.states is None:
            return []
        
        try:
            current_idx = self.states.index(start_state)
        except ValueError:
            return []
        
        simulation = [start_state]
        
        for _ in range(n_steps):
            # Obtener probabilidades de transici√≥n desde el estado actual
            probs = self.transition_matrix[current_idx]
            
            # Si no hay transiciones posibles, terminar
            if probs.sum() == 0:
                break
            
            # Seleccionar siguiente estado basado en probabilidades
            next_idx = np.random.choice(len(self.states), p=probs)
            next_state = self.states[next_idx]
            simulation.append(next_state)
            current_idx = next_idx
        
        return simulation

def create_transition_heatmap(analyzer, top_n=20):
    """Crea un mapa de calor de la matriz de transici√≥n"""
    if analyzer.transition_matrix is None:
        return None
    
    # Seleccionar las top_n estaciones m√°s activas
    activity = analyzer.transition_matrix.sum(axis=1) + analyzer.transition_matrix.sum(axis=0)
    top_indices = np.argsort(activity)[-top_n:]
    
    # Submatriz
    sub_matrix = analyzer.transition_matrix[np.ix_(top_indices, top_indices)]
    top_states = [analyzer.states[i] for i in top_indices]
    top_names = [analyzer.get_stop_name(state) for state in top_states]
    
    fig = px.imshow(
        sub_matrix,
        x=top_names,
        y=top_names,
        color_continuous_scale="Viridis",
        title=f"Matriz de Transici√≥n - Top {top_n} Estaciones M√°s Activas",
        labels=dict(x="Estaci√≥n Destino", y="Estaci√≥n Origen", color="Probabilidad")
    )
    
    fig.update_layout(
        height=600,
        xaxis_tickangle=-45,
        font_size=10
    )
    
    return fig

def create_network_graph(analyzer, threshold=0.1):
    """Crea un grafo de red de las transiciones"""
    if analyzer.transition_matrix is None:
        return None
    
    # Crear grafo dirigido
    G = nx.DiGraph()
    
    # Agregar nodos y aristas
    for i, from_state in enumerate(analyzer.states):
        for j, to_state in enumerate(analyzer.states):
            prob = analyzer.transition_matrix[i, j]
            if prob > threshold:  # Solo incluir transiciones significativas
                from_name = analyzer.get_stop_name(from_state)
                to_name = analyzer.get_stop_name(to_state)
                G.add_edge(from_name, to_name, weight=prob)
    
    # Calcular posiciones usando layout spring
    pos = nx.spring_layout(G, k=1, iterations=50)
    
    # Extraer coordenadas
    edge_x = []
    edge_y = []
    for edge in G.edges():
        x0, y0 = pos[edge[0]]
        x1, y1 = pos[edge[1]]
        edge_x.extend([x0, x1, None])
        edge_y.extend([y0, y1, None])
    
    # Crear trazas
    edge_trace = go.Scatter(
        x=edge_x, y=edge_y,
        line=dict(width=1, color='#888'),
        hoverinfo='none',
        mode='lines'
    )
    
    node_x = []
    node_y = []
    node_text = []
    for node in G.nodes():
        x, y = pos[node]
        node_x.append(x)
        node_y.append(y)
        node_text.append(node)
    
    node_trace = go.Scatter(
        x=node_x, y=node_y,
        mode='markers+text',
        hoverinfo='text',
        text=node_text,
        textposition="middle center",
        marker=dict(
            size=10,
            color='lightblue',
            line=dict(width=2, color='black')
        )
    )
    
    fig = go.Figure(data=[edge_trace, node_trace],
                   layout=go.Layout(
                       title=f'Red de Transiciones (umbral > {threshold})',
                       title_font_size=16,
                       showlegend=False,
                       hovermode='closest',
                       margin=dict(b=20,l=5,r=5,t=40),
                       annotations=[ dict(
                           text="Conexiones entre estaciones del Metrob√∫s",
                           showarrow=False,
                           xref="paper", yref="paper",
                           x=0.005, y=-0.002,
                           xanchor="left", yanchor="bottom",
                           font=dict(color="black", size=12)
                       )],
                       xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
                       yaxis=dict(showgrid=False, zeroline=False, showticklabels=False))
                   )
    
    return fig

def main():
    """Funci√≥n principal de la aplicaci√≥n"""
    st.title("üöå An√°lisis de Cadenas de Markov - Metrob√∫s CDMX")
    st.markdown("### An√°lisis de patrones de transici√≥n entre estaciones")
      # Inicializar analizador
    if 'analyzer' not in st.session_state:
        st.session_state.analyzer = MetrobusMarkovAnalyzer()
    
    analyzer = st.session_state.analyzer
      # Sidebar para configuraci√≥n
    st.sidebar.header("‚öôÔ∏è Configuraci√≥n")
      # Cargar datos
    if st.sidebar.button("üîÑ Cargar Datos"):
        with st.spinner("Cargando datos del Metrob√∫s..."):
            if analyzer.load_data():
                st.sidebar.success("‚úÖ Datos cargados exitosamente")
                st.session_state.data_loaded = True
            else:
                st.sidebar.error("‚ùå Error al cargar datos")
                st.session_state.data_loaded = False
    
    # No necesitamos recuperar analyzer de session_state ya que lo tenemos
      # Verificar si los datos est√°n cargados
    if not hasattr(st.session_state, 'data_loaded') or not st.session_state.data_loaded:
        st.info("üëÜ Haz clic en 'Cargar Datos' en la barra lateral para comenzar")
        return
      # Verificar que el analyzer tenga los datos cargados
    if not analyzer.is_data_loaded():
        st.error("‚ùå Error: Los datos no est√°n disponibles en el analizador. Intenta cargar de nuevo.")
        st.session_state.data_loaded = False
        return
    
    # Procesar datos y estimar matriz
    if st.sidebar.button("üßÆ Calcular Matriz de Transici√≥n"):
        with st.spinner("Procesando secuencias de viajes..."):
            try:
                sequences = analyzer.preprocess_data()
                st.sidebar.info(f"üìä Se procesaron {len(sequences)} secuencias de viajes")
            except ValueError as e:
                st.error(f"‚ùå Error al procesar datos: {e}")
                return
            
        with st.spinner("Estimando matriz de transici√≥n..."):
            analyzer.estimate_transition_matrix(sequences)
            st.sidebar.success("‚úÖ Matriz calculada")
            st.session_state.matrix_calculated = True
      # Verificar si la matriz est√° calculada
    if not hasattr(st.session_state, 'matrix_calculated') or not st.session_state.matrix_calculated:
        st.info("üëÜ Haz clic en 'Calcular Matriz de Transici√≥n' para continuar")
        return
    
    # Verificar que los datos est√©n disponibles
    if analyzer.states is None or analyzer.transition_matrix is None:
        st.error("‚ùå Error: Los datos no est√°n disponibles. Intenta cargar y calcular de nuevo.")
        return
    
    # Mostrar estad√≠sticas b√°sicas
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("üöâ Total Estaciones", len(analyzer.states))
    
    with col2:
        st.metric("üîó Transiciones Posibles", f"{len(analyzer.states)**2:,}")
    
    with col3:
        non_zero = np.count_nonzero(analyzer.transition_matrix)
        st.metric("‚úÖ Transiciones Activas", f"{non_zero:,}")
    
    with col4:
        sparsity = (1 - non_zero / len(analyzer.states)**2) * 100
        st.metric("üìâ Dispersi√≥n", f"{sparsity:.1f}%")
    
    # Tabs para diferentes an√°lisis
    tab1, tab2, tab3, tab4, tab5 = st.tabs(["üî• Matriz de Calor", "üï∏Ô∏è Red de Conexiones", "üéØ Simulaci√≥n", "üìä Estad√≠sticas", "üö¶ MDP Headway Control"])
    
    with tab1:
        st.subheader("Matriz de Transici√≥n")
        
        top_n = st.slider("N√∫mero de estaciones a mostrar", 10, 50, 20)
        fig_heatmap = create_transition_heatmap(analyzer, top_n)
        
        if fig_heatmap:
            st.plotly_chart(fig_heatmap, use_container_width=True)
        
        st.info("üí° **Interpretaci√≥n**: Los colores m√°s brillantes indican mayor probabilidad de transici√≥n entre estaciones.")
    
    with tab2:
        st.subheader("Red de Conexiones")
        
        threshold = st.slider("Umbral m√≠nimo de probabilidad", 0.01, 0.5, 0.1, 0.01)
        fig_network = create_network_graph(analyzer, threshold)
        
        if fig_network:
            st.plotly_chart(fig_network, use_container_width=True)
        
        st.info("üí° **Interpretaci√≥n**: Los nodos representan estaciones y las conexiones muestran transiciones frecuentes.")
    
    with tab3:
        st.subheader("Simulaci√≥n de Rutas")
        
        col1, col2 = st.columns([1, 1])
        
        with col1:
            # Seleccionar estaci√≥n inicial
            station_names = [analyzer.get_stop_name(state) for state in analyzer.states]
            selected_station_name = st.selectbox("Estaci√≥n inicial", station_names)
            
            # Encontrar el stop_id correspondiente
            selected_station_id = None
            for state in analyzer.states:
                if analyzer.get_stop_name(state) == selected_station_name:
                    selected_station_id = state
                    break
        
        with col2:
            n_steps = st.slider("N√∫mero de pasos", 5, 20, 10)
        
        if st.button("üöÄ Simular Ruta"):
            if selected_station_id:
                simulation = analyzer.simulate_markov_chain(selected_station_id, n_steps)
                
                if simulation:
                    st.subheader("üõ§Ô∏è Ruta Simulada:")
                    
                    # Crear DataFrame para mostrar la ruta
                    route_data = []
                    for i, stop_id in enumerate(simulation):
                        route_data.append({
                            'Paso': i + 1,
                            'Estaci√≥n': analyzer.get_stop_name(stop_id),
                            'ID': stop_id
                        })
                    
                    route_df = pd.DataFrame(route_data)
                    st.dataframe(route_df, use_container_width=True)
                    
                    # Visualizar como gr√°fico de l√≠nea
                    fig_route = px.line(
                        route_df, 
                        x='Paso', 
                        y='Estaci√≥n',
                        title="Trayectoria Simulada",
                        markers=True
                    )
                    fig_route.update_layout(height=400)
                    st.plotly_chart(fig_route, use_container_width=True)
                else:
                    st.error("No se pudo simular la ruta desde esta estaci√≥n")
    
    with tab4:
        st.subheader("Estad√≠sticas de la Matriz de Transici√≥n")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # Estaciones m√°s conectadas (outgoing)
            outgoing_connections = analyzer.transition_matrix.sum(axis=1)
            top_outgoing_idx = np.argsort(outgoing_connections)[-10:]
            
            outgoing_data = []
            for idx in reversed(top_outgoing_idx):
                station_name = analyzer.get_stop_name(analyzer.states[idx])
                outgoing_data.append({
                    'Estaci√≥n': station_name,
                    'Conexiones Salientes': outgoing_connections[idx]
                })
            
            st.subheader("üîù Top 10 - M√°s Conexiones Salientes")
            st.dataframe(pd.DataFrame(outgoing_data), use_container_width=True)
        
        with col2:
            # Estaciones m√°s conectadas (incoming)
            incoming_connections = analyzer.transition_matrix.sum(axis=0)
            top_incoming_idx = np.argsort(incoming_connections)[-10:]
            
            incoming_data = []
            for idx in reversed(top_incoming_idx):
                station_name = analyzer.get_stop_name(analyzer.states[idx])
                incoming_data.append({
                    'Estaci√≥n': station_name,
                    'Conexiones Entrantes': incoming_connections[idx]
                })
            
            st.subheader("üéØ Top 10 - M√°s Conexiones Entrantes")
            st.dataframe(pd.DataFrame(incoming_data), use_container_width=True)
    
    with tab5:
        st.subheader("üö¶ Modelo MDP de Control de Headway (Holding)")
        
        st.markdown("""
        **Modelo 2 (Avanzado) ‚Äì MDP de Control de Headway**
        
        Este modelo implementa un Proceso de Decisi√≥n de Markov para optimizar el control de headway 
        (intervalo entre autobuses) mediante estrategias de holding.
        """)
        
        # Par√°metros del modelo MDP
        st.subheader("‚öôÔ∏è Configuraci√≥n del Modelo MDP")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**Estados del Sistema:**")
            st.write("‚Ä¢ **delay**: Retraso actual (-3, 0-3, >3 min)")
            st.write("‚Ä¢ **gapPrev**: Intervalo con autob√∫s anterior")
            st.write("‚Ä¢ **gapNext**: Intervalo con autob√∫s siguiente")
            
            # Par√°metros configurables
            delay_bins = st.selectbox(
                "Discretizaci√≥n de delay (minutos):",
                [(-3, 0, 3), (-5, 0, 5), (-2, 0, 2)]
            )
            
            gap_threshold = st.slider(
                "Umbral de gap (minutos):",
                min_value=2,
                max_value=10,
                value=5
            )
        
        with col2:
            st.markdown("**Acciones Disponibles:**")
            
            # Configurar acciones
            hold_actions = st.multiselect(
                "Tiempos de holding (segundos):",
                [0, 30, 60, 90, 120],
                default=[0, 30, 60]
            )
            
            include_skip = st.checkbox("Incluir acci√≥n 'Skip'", value=False)
            
            # Par√°metro lambda para la funci√≥n de recompensa
            lambda_param = st.slider(
                "Œª (balance comodidad vs ritmo):",
                min_value=0.1,
                max_value=2.0,
                value=0.5,
                step=0.1
            )
        
        # Funci√≥n de recompensa
        st.subheader("üí∞ Funci√≥n de Recompensa")
        st.latex(r'''
        R(s,a) = -(\text{waiting\_time\_passengers}) - \lambda \cdot (\text{hold\_time})
        ''')
        
        st.write(f"**Par√°metro actual:** Œª = {lambda_param}")
        st.write("‚Ä¢ **Objetivo**: Minimizar tiempo de espera de pasajeros y tiempo de holding")
        st.write("‚Ä¢ **Balance**: Œª controla el trade-off entre comodidad del pasajero y eficiencia operacional")
          # Simulaci√≥n del MDP
        st.subheader("üéÆ Simulaci√≥n del MDP")
        
        # Crear estados discretos (definir fuera del condicional)
        delay_states = list(range(-3, 4))  # -3 a 3 minutos
        gap_states = list(range(0, gap_threshold + 1))  # 0 a gap_threshold minutos
        
        if st.button("üöÄ Simular MDP de Headway Control"):
            with st.spinner("Generando simulaci√≥n MDP..."):
                # Los estados ya est√°n definidos arriba
                
                # Generar datos simulados para demostraci√≥n
                n_simulations = 100
                results = []
                
                for i in range(n_simulations):
                    # Estado inicial aleatorio
                    delay = np.random.choice(delay_states)
                    gap_prev = np.random.choice(gap_states)
                    gap_next = np.random.choice(gap_states)
                    
                    # Acci√≥n aleatoria para baseline
                    action = np.random.choice(hold_actions)
                    
                    # Calcular recompensa simulada
                    waiting_time = max(0, delay + gap_prev) * np.random.uniform(5, 15)  # pasajeros esperando
                    hold_cost = action * lambda_param
                    reward = -(waiting_time + hold_cost)
                    
                    results.append({
                        'Simulaci√≥n': i + 1,
                        'Delay (min)': delay,
                        'Gap Prev (min)': gap_prev,
                        'Gap Next (min)': gap_next,
                        'Acci√≥n (seg)': action,
                        'Tiempo Espera': waiting_time,
                        'Costo Holding': hold_cost,
                        'Recompensa': reward
                    })
                
                # Mostrar resultados
                results_df = pd.DataFrame(results)
                
                # Estad√≠sticas principales
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    avg_reward = results_df['Recompensa'].mean()
                    st.metric("Recompensa Promedio", f"{avg_reward:.2f}")
                
                with col2:
                    avg_waiting = results_df['Tiempo Espera'].mean()
                    st.metric("Tiempo Espera Promedio", f"{avg_waiting:.1f} min")
                
                with col3:
                    avg_holding = results_df['Costo Holding'].mean()
                    st.metric("Costo Holding Promedio", f"{avg_holding:.2f}")
                
                # Gr√°fico de recompensas por acci√≥n
                fig_rewards = px.box(
                    results_df,
                    x='Acci√≥n (seg)',
                    y='Recompensa',
                    title="Distribuci√≥n de Recompensas por Acci√≥n de Holding"
                )
                st.plotly_chart(fig_rewards, use_container_width=True)
                
                # Heatmap de estados vs recompensas
                pivot_data = results_df.groupby(['Delay (min)', 'Gap Prev (min)'])['Recompensa'].mean().unstack()
                
                fig_heatmap = go.Figure(data=go.Heatmap(
                    z=pivot_data.values,
                    x=pivot_data.columns,
                    y=pivot_data.index,
                    colorscale='RdYlBu',
                    colorbar=dict(title="Recompensa Promedio")
                ))
                
                fig_heatmap.update_layout(
                    title="Heatmap: Recompensa por Estado (Delay vs Gap Previo)",
                    xaxis_title="Gap Previo (min)",
                    yaxis_title="Delay (min)"
                )
                st.plotly_chart(fig_heatmap, use_container_width=True)
                
                # Mostrar tabla de resultados (primeros 20)
                st.subheader("üìã Resultados Detallados (Primeras 20 simulaciones)")
                st.dataframe(results_df.head(20), use_container_width=True)
        
        # Informaci√≥n adicional sobre el modelo
        st.subheader("üìà Resultados Esperados del Modelo")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("""
            **M√©tricas de Mejora:**
            ‚Ä¢ **Headway Variance**: ‚Üì 15-25%
            ‚Ä¢ **Tiempo de Espera Medio**: ‚Üì 10-20%
            ‚Ä¢ **Regularidad del Servicio**: ‚Üë 20-30%
            ‚Ä¢ **Satisfacci√≥n del Usuario**: ‚Üë 15-25%
            """)
        
        with col2:
            st.markdown("""
            **M√©todos de Soluci√≥n:**
            ‚Ä¢ **Iteraci√≥n de Valores**: Para espacios de estado peque√±os
            ‚Ä¢ **Q-Learning Tabular**: Aprendizaje por refuerzo
            ‚Ä¢ **Policy Iteration**: Optimizaci√≥n directa de pol√≠tica
            ‚Ä¢ **SARSA**: Alternativa m√°s conservadora a Q-Learning
            """)
        
        # Algoritmo de soluci√≥n
        st.subheader("üßÆ Algoritmo de Soluci√≥n - Value Iteration")
        
        if st.button("üî¨ Ejecutar Value Iteration (Demo)"):
            with st.spinner("Ejecutando iteraci√≥n de valores..."):
                # Implementaci√≥n simplificada de Value Iteration
                n_states = len(delay_states) * len(gap_states) * len(gap_states)
                n_actions = len(hold_actions)
                
                # Inicializar valores
                V = np.zeros(n_states)
                policy = np.zeros(n_states, dtype=int)
                
                # Par√°metros del algoritmo
                gamma = 0.95  # Factor de descuento
                theta = 0.01  # Umbral de convergencia
                max_iterations = 50
                
                convergence_history = []
                
                for iteration in range(max_iterations):
                    V_old = V.copy()
                    
                    for state in range(n_states):
                        # Simular Q-values para cada acci√≥n
                        q_values = []
                        for action_idx, action in enumerate(hold_actions):
                            # Recompensa inmediata simulada
                            immediate_reward = -np.random.uniform(10, 50) - lambda_param * action
                            
                            # Valor esperado del siguiente estado (simplificado)
                            next_value = gamma * np.random.uniform(0, 1) * V[state]
                            
                            q_value = immediate_reward + next_value
                            q_values.append(q_value)
                        
                        # Actualizar valor y pol√≠tica
                        V[state] = max(q_values)
                        policy[state] = np.argmax(q_values)
                    
                    # Verificar convergencia
                    delta = np.max(np.abs(V - V_old))
                    convergence_history.append(delta)
                    
                    if delta < theta:
                        st.success(f"‚úÖ Convergencia alcanzada en {iteration + 1} iteraciones")
                        break
                  # Mostrar convergencia
                fig_conv = px.line(
                    x=range(len(convergence_history)),
                    y=convergence_history,
                    title="Convergencia del Value Iteration",
                    labels={'x': 'Iteraci√≥n', 'y': 'Delta (Cambio m√°ximo en V)'}
                )
                fig_conv.add_hline(y=theta, line_dash="dash", line_color="red", 
                                 annotation_text="Umbral de convergencia")
                st.plotly_chart(fig_conv, use_container_width=True)
                
                # Mostrar pol√≠tica √≥ptima
                policy_actions = [hold_actions[i] for i in policy[:20]]  # Primeros 20 estados
                
                policy_df = pd.DataFrame({
                    'Estado': range(20),
                    'Acci√≥n √ìptima (seg)': policy_actions,
                    'Valor del Estado': V[:20]
                })
                
                st.subheader("üéØ Pol√≠tica √ìptima (Primeros 20 Estados)")
                st.dataframe(policy_df, use_container_width=True)
        
        # Notas t√©cnicas
        st.subheader("üìù Notas T√©cnicas del Modelo")
        st.markdown("""
        **Consideraciones de Implementaci√≥n:**
        
        1. **Discretizaci√≥n del Estado**: El espacio continuo de delays y gaps se discretiza para hacer el problema tratable computacionalmente.
        
        2. **Funci√≥n de Transici√≥n**: Las probabilidades de transici√≥n se pueden estimar de datos hist√≥ricos de tr√°fico o usar modelos param√©tricos.
        
        3. **Escalabilidad**: Para redes m√°s grandes, considerar:
           - Approximate Dynamic Programming
           - Function Approximation
           - Deep Q-Networks (DQN)
        
        4. **Validaci√≥n**: El modelo debe calibrarse con datos reales y validarse mediante simulaci√≥n antes de implementaci√≥n.
        
        5. **Restricciones Operacionales**: Incluir l√≠mites en tiempos de holding y consideraciones de capacidad de las estaciones.
        """)

    # Footer
    st.markdown("---")
    st.markdown(
        """
        <div style='text-align: center; color: #666;'>
            üíª Desarrollado para an√°lisis de transporte p√∫blico | 
            üöå Datos del Metrob√∫s CDMX | 
            üìä Cadenas de Markov
        </div>
        """, 
        unsafe_allow_html=True
    )

if __name__ == "__main__":
    main()
